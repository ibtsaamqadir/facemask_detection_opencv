{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaFK2w1Es0yy"
      },
      "source": [
        "Mouting the Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbpE_e4qqiK6",
        "outputId": "873cd06f-575b-413f-ccd8-00581821e2dc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS_oYg5Ls5D6"
      },
      "source": [
        "Changing the directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CYlxZ8dq_0i",
        "outputId": "e472ec1d-6169-41e7-e9aa-0a72cf61192f"
      },
      "outputs": [],
      "source": [
        "cd drive/MyDrive/Computer\\ Vision/Dataset_project/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O6Vhrj2s7oF"
      },
      "source": [
        "Import necessary packages and libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3AkVjkqrFEL"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import load_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdUOwDaUfVWe"
      },
      "source": [
        "Importing cv2_imshow because colab does not support cv2.imshow()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIYdn1woOS1n"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkPnPDCZfknN"
      },
      "source": [
        "Loading the model trained using the Training data set and Keras "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6SzuofrrJM5"
      },
      "outputs": [],
      "source": [
        "model=load_model(\"./model2-009.model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRni2-y6fwrq"
      },
      "source": [
        "Python Script for using builtin webcam using Colab "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwnUIwY_r1nK"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJCV8Pnvr1nL"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-IKERV_f-IR"
      },
      "source": [
        "Using HAARCASCADE Classifier to detect face in the image captured"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2duMLt6rLYH"
      },
      "outputs": [],
      "source": [
        "labels_dict={0:'without mask',1:'mask'}\n",
        "color_dict={0:(0,0,255),1:(0,255,0)}\n",
        "\n",
        "size = 4\n",
        "classifier = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCh4b2X_xLwJ"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "    try:\n",
        "      filename = take_photo()\n",
        "      print('Saved to {}'.format(filename))\n",
        "  \n",
        "      # Show the image which was just taken.\n",
        "      display(Image(filename))\n",
        "    except Exception as err:\n",
        "      # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "      # grant the page permission to access it.\n",
        "      print(str(err))\n",
        "\n",
        "    img=cv2.imread('photo.jpg', cv2.IMREAD_UNCHANGED)\n",
        "    img=cv2.flip(img,1,1)\n",
        "    mini = cv2.resize(img, (img.shape[1] // size, img.shape[0] // size))\n",
        "    faces = classifier.detectMultiScale(mini)\n",
        "    for f in faces:\n",
        "        (x, y, w, h) = [v * size for v in f]\n",
        "        img_f = img[y:y+h, x:x+w]\n",
        "        resized=cv2.resize(img_f,(150,150))\n",
        "        normalized=resized/255.0\n",
        "        reshaped=np.reshape(normalized,(1,150,150,3))\n",
        "        reshaped = np.vstack([reshaped])\n",
        "        result=model.predict(reshaped)\n",
        "        #print(result)\n",
        "        \n",
        "        label=np.argmax(result,axis=1)[0]\n",
        "      \n",
        "        cv2.rectangle(img,(x,y),(x+w,y+h),color_dict[label],2)\n",
        "        cv2.rectangle(img,(x,y-40),(x+w,y),color_dict[label],-1)\n",
        "        cv2.putText(img, labels_dict[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
        "        \n",
        "    cv2_imshow(img)\n",
        "    cv2.waitKey(0)\n",
        "    stop = str(input('Press x if you want to stop executing'))\n",
        "    if stop == 'x': \n",
        "        break\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
